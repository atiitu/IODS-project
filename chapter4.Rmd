---
title: "Untitled"
author: "Anna Syreeni"
date: "21 marraskuuta 2018"
output: html_document
---

#Week4: Clustering and classification

**Exploring Boston-data**

For this week's excersize we'll use a Boston-dataset included in the MASS Package in R. Basically, the data is about per capita crime rate by town and some variables describing the towns. There are 14 variables on 506 towns included.

```{r, echo=FALSE, results=FALSE}
library(MASS)
data("Boston")
str(Boston)
summary(Boston)
```

 
The variables in the Boston data are:<br/>
crim = per capita crime rate by town<br/>
zn = proportion of residential land zoned for lots over 25,000 sq.ft<br/> 
indus = proportion of non-retail business acres per town<br/> 
chas = Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)<br/>
nox = nitrogen oxides concentration (parts per 10 million)<br/> 
rm  = average number of rooms per dwelling<br/>
age = proportion of owner-occupied units built prior to 1940<br/>
dis = weighted mean of distances to five Boston employment centres<br/>
rad = index of accessibility to radial highways<br/>
tax = full-value property-tax rate per \$10,000<br/>
ptratio = pupil-teacher ratio by town<br/>
black = 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town<br/> 
lstat  = lower status of the population (percent)<br/>
medv = median value of owner-occupied homes in \$1000s<br/> 


The summaries of all variables are listed below. As seen from the summary, for example crime rate differs largely between towns: it ranges from 0.006 crimes from 89.0 crimes per capita.

```{r, echo=FALSE, results=TRUE}
summary(Boston)
```

```{r, echo=FALSE, results=FALSE, include=FALSE}
cor_matrix <- cor(Boston) 
round(cor_matrix, 2)
```

As seen from the correlation matrix, for example accessibility to radial highways (rad, calculated correlation r=0.63) and full-value propery-tax rate (tax, calculated r = 0.58) correlate positively with per capita crime rate. Living far Boston five Boston employment centres associates  with lower air nitric oxide concentration (correlation of dis and nos, r = -0.77)

```{r, echo=FALSE, results=FALSE, message=FALSE}
library(tidyverse)
library(corrplot)
corrplot(cor_matrix)
```

Next I standarsized all variables in the Boston data. Summaries of the variables are printed below. You can easily see that all standarized variables now have a mean of 0.

```{r, echo=FALSE, message=FALSE}
# center and standardize variables
boston_scaled <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled)
```

For further analysis, a cathegorical variable from the scaled crime rate was created (quartiles). This variable now divides the crime rate to "low", "medium low", "medium high" and  "high" -cathegories.

```{r, echo=FALSE, message=FALSE}
# center and standardize variables
boston_scaled <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled)

# class of the boston_scaled object
#class(boston_scaled)

# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)

# summary of the scaled crime rate
# summary(boston_scaled$crim)

# create a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
#bins

# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, 
             label = c("low", "med_low", "med_high", "high"))

# look at the table of the new factor crime
# table(crime)

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
```

Next the Boston data was divided into training and test sets. Randomly chosen 80% belongs to the training set, and the rest is in test-set.

```{r, echo=FALSE, message=FALSE, results=FALSE}
# number of rows in the Boston dataset 
n <- nrow(boston_scaled)
#n
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
#ind #random row numbers saved

# create train set
train <- boston_scaled[ind,]
#class(train) # now a smaller train data.frame was generated with random rows

# create test set 
test <- boston_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test$crime

# remove the crime variable from test data
library(dplyr)
test <- dplyr::select(test, -crime)
```

**Linear discrimant analysis**

Linear discrimant analysis of the Boston data shows that variable rad meaning accessibility to radial highways, is a very strong predictor for a town to belong to a group of high crime rate.


```{r, echo=FALSE, message=FALSE}
lda.fit <- lda(crime ~ ., data = train)

# print the lda.fit object
#lda.fit

# the function for lda biplot arrows
# arrow and text color set to black
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col="black", length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col="black", pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
# all was black before adding the col and pch
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2)

# lda.fit, correct_classes and test are available
#?predict.lda

# predict classes with test data
#lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
#table(correct = correct_classes, predicted = lda.pred$class)
```

The lda-model predicts very well the belonging to the high crime rate -cathegory.As seen from the propability table below, 96.6% of the observations in high- crime rate cathegory were correcly classified to the high crime rate group. 

For the other cathegories, LDA performs less well for other groups: For example, only 55.2% towns in the true lowest crime-rate group were correctly classified. The rest (44.8%) were classified to the next group (medium low) group, which shows that LDA had troubles classifing the low and medium low groups.


**NOTE ** The numbers might change between different knittings, because the code is run again and the random sample selected for creating the training set differs slightly. Anyway, the interpretaions remain the same that high crime rate group is nicely predicted.

```{r, echo=FALSE, message=FALSE, results=TRUE}
# correct_classes already saved from the test-set and then removed
#?predict.lda

# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
mytable <- table(correct = correct_classes, predicted = lda.pred$class)
mytable

prop.table(mytable, 1) %>% round(5)
```






```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
